# ğŸ¯ Sistema de DetecciÃ³n y Seguimiento de Objetos en Tiempo Real

Un sistema completo de visiÃ³n por computador que integra mÃºltiples tÃ©cnicas avanzadas para la detecciÃ³n, seguimiento y anÃ¡lisis de objetos en video en tiempo real.

## ğŸŒŸ CaracterÃ­sticas Principales

- **ğŸ” DetecciÃ³n con YOLO**: DetecciÃ³n precisa de objetos usando YOLOv8
- **ğŸ¯ Seguimiento con DeepSORT**: Seguimiento robusto con IDs consistentes
- **ğŸ“ CÃ¡lculo de MÃ©tricas**: Velocidad, distancia recorrida y anÃ¡lisis de trayectorias
- **ğŸ¨ VisualizaciÃ³n en Tiempo Real**: Renderizado avanzado con trayectorias y estadÃ­sticas
- **ğŸ¬ GrabaciÃ³n y GIFs**: Captura automÃ¡tica de escenas interesantes
- **ğŸ–¥ï¸ Interfaz GrÃ¡fica**: GUI intuitiva con PySimpleGUI
- **âš™ï¸ ConfiguraciÃ³n Flexible**: Sistema de configuraciÃ³n YAML completo

## ğŸ—ï¸ Arquitectura del Sistema

```
[Video Input] â†’ FrameReader â†’ Detector (YOLO) â†’ Tracker (DeepSORT) 
                                    â†“
[Output & GIFs] â† Recorder â† Visualizer â† MetricsCalculator
```

### Componentes Principales

| Componente | FunciÃ³n | TecnologÃ­a |
|------------|---------|------------|
| **FrameReader** | Lectura de video/cÃ¡mara | OpenCV |
| **Detector** | DetecciÃ³n de objetos | YOLOv8 (Ultralytics) |
| **Tracker** | Seguimiento de objetos | DeepSORT |
| **MetricsCalculator** | CÃ¡lculo de velocidad/distancia | NumPy/SciPy |
| **Visualizer** | Renderizado en tiempo real | OpenCV |
| **Recorder** | GrabaciÃ³n de videos/GIFs | ImageIO |

## ğŸš€ InstalaciÃ³n

### 1. Clonar el Repositorio

```bash
git clone <repository-url>
cd parcial-visual
```

### 2. Crear Entorno Virtual (Recomendado)

```bash
python -m venv venv
# Windows
venv\Scripts\activate
# Linux/Mac
source venv/bin/activate
```

### 3. Instalar Dependencias

```bash
pip install -r requirements.txt
```

### 4. Descargar Modelos (Opcional)

Los modelos YOLO se descargan automÃ¡ticamente en el primer uso. Para modelos especÃ­ficos:

```bash
# Crear carpeta de modelos
mkdir models

# Descargar modelos manualmente (opcional)
# Los modelos se descargan automÃ¡ticamente: yolov8n.pt, yolov8s.pt, etc.
```

## ğŸ® Uso del Sistema

### Modo Comando (Terminal)

```bash
# Usar cÃ¡mara por defecto
python main.py

# Usar archivo de video especÃ­fico
python main.py --source video.mp4

# Usar cÃ¡mara especÃ­fica
python main.py --source 1

# Modo headless (sin ventana)
python main.py --headless --record

# ConfiguraciÃ³n personalizada
python main.py --confidence 0.7 --device cuda --pixels-per-meter 100
```

#### Controles del Teclado

- **Q**: Salir del programa
- **ESPACIO**: Pausar/Reanudar procesamiento
- **R**: Iniciar/Detener grabaciÃ³n manual
- **G**: Crear GIF del buffer actual
- **S**: Mostrar estadÃ­sticas detalladas

### Modo Interfaz GrÃ¡fica

```bash
python gui_app.py
```

La interfaz grÃ¡fica proporciona:
- Control visual de todos los parÃ¡metros
- VisualizaciÃ³n en tiempo real
- EstadÃ­sticas actualizadas
- Controles de grabaciÃ³n intuitivos

## âš™ï¸ ConfiguraciÃ³n

El sistema utiliza un archivo de configuraciÃ³n YAML ubicado en `config/config.yaml`:

### ConfiguraciÃ³n del Detector YOLO

```yaml
detector:
  model_path: "models/yolov8n.pt"  # Modelo a usar
  confidence_threshold: 0.5         # Umbral de confianza
  iou_threshold: 0.45              # Umbral IoU para NMS
  device: "cpu"                    # "cpu" o "cuda"
  classes_to_detect: []            # Clases especÃ­ficas o [] para todas
```

### ConfiguraciÃ³n del Tracker

```yaml
tracker:
  max_age: 50          # Frames mÃ¡ximos sin detecciÃ³n
  min_hits: 3          # Detecciones mÃ­nimas para confirmar
  iou_threshold: 0.3   # Umbral IoU para asociaciÃ³n
```

### ConfiguraciÃ³n de MÃ©tricas

```yaml
metrics:
  pixels_per_meter: 50  # CalibraciÃ³n espacial
  fps: 30              # FPS del video
  velocity_smoothing_window: 10  # Ventana para suavizado
```

### ConfiguraciÃ³n del Visualizador

```yaml
visualizer:
  show_trajectory: true      # Mostrar trayectorias
  trajectory_length: 30      # Puntos en trayectoria
  show_velocity: true        # Mostrar velocidad
  show_distance: true        # Mostrar distancia
```

## ğŸ“ Estructura del Proyecto

```
parcial-visual/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ core/                    # MÃ³dulos principales
â”‚   â”‚   â”œâ”€â”€ frame_reader.py      # Lectura de video
â”‚   â”‚   â”œâ”€â”€ detector.py          # DetecciÃ³n YOLO
â”‚   â”‚   â”œâ”€â”€ tracker.py           # Seguimiento DeepSORT
â”‚   â”‚   â”œâ”€â”€ metrics_calculator.py # CÃ¡lculo de mÃ©tricas
â”‚   â”‚   â”œâ”€â”€ visualizer.py        # Renderizado
â”‚   â”‚   â””â”€â”€ recorder.py          # GrabaciÃ³n
â”‚   â””â”€â”€ utils/
â”‚       â””â”€â”€ config_loader.py     # GestiÃ³n de configuraciÃ³n
â”œâ”€â”€ config/
â”‚   â””â”€â”€ config.yaml              # ConfiguraciÃ³n principal
â”œâ”€â”€ models/                      # Modelos pre-entrenados
â”œâ”€â”€ data/                        # Videos de entrada
â”œâ”€â”€ output/                      # Resultados generados
â”œâ”€â”€ main.py                      # AplicaciÃ³n principal
â”œâ”€â”€ gui_app.py                   # Interfaz grÃ¡fica
â”œâ”€â”€ requirements.txt             # Dependencias
â””â”€â”€ README.md                    # Esta documentaciÃ³n
```

## ğŸ¬ Salida del Sistema

### Videos Generados

- `session_YYYYMMDD_HHMMSS.mp4`: Grabaciones de sesiÃ³n completa
- `auto_recording_YYYYMMDD_HHMMSS.mp4`: Grabaciones automÃ¡ticas de escenas activas
- `manual_HHMMSS.mp4`: Grabaciones manuales iniciadas por el usuario

### GIFs Creados

- `tracking_gif_YYYYMMDD_HHMMSS.gif`: GIFs del buffer actual
- `session_final.gif`: GIF resumen de la sesiÃ³n
- `auto_recording_YYYYMMDD_HHMMSS.gif`: GIFs automÃ¡ticos de escenas activas

### MÃ©tricas Exportables

```python
# Exportar mÃ©tricas a CSV
metrics_calculator.export_metrics_csv('output/metrics.csv')
```

## ğŸ“Š MÃ©tricas Calculadas

### Por Objeto

- **Velocidad instantÃ¡nea**: En pÃ­xeles/frame y m/s
- **Velocidad promedio**: Suavizada en ventana temporal
- **Distancia recorrida**: Total acumulada en metros
- **AceleraciÃ³n**: Cambio de velocidad en m/sÂ²
- **Suavidad de trayectoria**: Ãndice de consistencia (0-1)

### Globales del Sistema

- **FPS de procesamiento**: Rendimiento en tiempo real
- **NÃºmero de tracks activos**: Objetos siendo seguidos
- **EstadÃ­sticas de velocidad**: Promedio y mÃ¡ximo
- **Distancia total**: Suma de todas las trayectorias

## ğŸ”§ PersonalizaciÃ³n y ExtensiÃ³n

### Agregar Nuevas Clases de DetecciÃ³n

```python
# En config.yaml
detector:
  classes_to_detect: [0, 1, 2]  # person, bicycle, car
```

### CalibraciÃ³n Espacial

Para medir distancias reales:

1. Medir una distancia conocida en pÃ­xeles en el video
2. Calcular `pixels_per_meter = pixels_medidos / metros_reales`
3. Actualizar en configuraciÃ³n o GUI

### Personalizar VisualizaciÃ³n

```python
# Modificar colores en config.yaml
visualizer:
  bbox_colors:
    - [255, 0, 0]    # Azul
    - [0, 255, 0]    # Verde
    - [0, 0, 255]    # Rojo
```

## ğŸ› SoluciÃ³n de Problemas

### Error: "YOLO no estÃ¡ disponible"

```bash
pip install ultralytics
```

### Error: "DeepSORT no estÃ¡ disponible"

```bash
pip install deep-sort-realtime
```

### Error: "No se puede abrir la cÃ¡mara"

- Verificar que la cÃ¡mara no estÃ© en uso por otra aplicaciÃ³n
- Probar con diferente `camera_id` (0, 1, 2...)
- En Linux, verificar permisos de cÃ¡mara

### Error: "Modelo YOLO no encontrado"

- Los modelos se descargan automÃ¡ticamente en el primer uso
- Verificar conexiÃ³n a internet
- Usar modelo local: colocar archivo `.pt` en carpeta `models/`

### Rendimiento Lento

1. **Usar modelo YOLO mÃ¡s ligero**: `yolov8n.pt` en lugar de `yolov8x.pt`
2. **Reducir resoluciÃ³n**: Configurar `frame_width` y `frame_height` mÃ¡s bajos
3. **Usar GPU**: Instalar PyTorch con CUDA y configurar `device: "cuda"`
4. **Saltar frames**: Configurar `skip_frames > 0`

## ğŸ† Casos de Uso

### AnÃ¡lisis de TrÃ¡fico

```yaml
# ConfiguraciÃ³n para vehÃ­culos
detector:
  classes_to_detect: [1, 2, 3, 5, 7]  # bicycle, car, motorcycle, bus, truck
metrics:
  pixels_per_meter: 20  # Ajustar segÃºn distancia de cÃ¡mara
```

### AnÃ¡lisis Deportivo

```yaml
# ConfiguraciÃ³n para personas
detector:
  classes_to_detect: [0]  # person
  confidence_threshold: 0.3  # MÃ¡s sensible
metrics:
  pixels_per_meter: 100  # Campo mÃ¡s cercano
  velocity_smoothing_window: 5  # Respuesta mÃ¡s rÃ¡pida
```

### Seguridad y Vigilancia

```yaml
# DetecciÃ³n general con auto-grabaciÃ³n
detector:
  confidence_threshold: 0.6  # Menos falsos positivos
recorder:
  auto_record_interesting_scenes: true
  min_objects_for_recording: 1  # Grabar con cualquier objeto
```

## ğŸ¤ ContribuciÃ³n

1. Fork el repositorio
2. Crear rama para nueva caracterÃ­stica: `git checkout -b feature/nueva-caracteristica`
3. Commit cambios: `git commit -m 'Agregar nueva caracterÃ­stica'`
4. Push a la rama: `git push origin feature/nueva-caracteristica`
5. Crear Pull Request

## ğŸ“„ Licencia

Este proyecto estÃ¡ bajo la Licencia MIT - ver archivo [LICENSE](LICENSE) para detalles.

## ğŸ™ Agradecimientos

- **Ultralytics** por YOLOv8
- **DeepSORT** por el algoritmo de tracking
- **OpenCV** por las herramientas de visiÃ³n por computador
- **PySimpleGUI** por la interfaz grÃ¡fica

## ğŸ“ Soporte

Para problemas, preguntas o sugerencias:

1. Revisar la secciÃ³n de [SoluciÃ³n de Problemas](#-soluciÃ³n-de-problemas)
2. Buscar en [Issues existentes](../../issues)
3. Crear un [nuevo Issue](../../issues/new) si es necesario

---

**Desarrollado para el Parcial de Visual Computing** ğŸ“ 